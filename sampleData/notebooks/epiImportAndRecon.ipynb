{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import   os\n",
    "import   sys\n",
    "sys.path.insert(0, os.path.abspath('.'))\n",
    "from     ismrmrdUtils   import   rawMRutils\n",
    "import   numpy          as       np\n",
    "import   ismrmrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First - read in (fully sampled) EPI data from array coil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataHeader, dataArray, refDataArray = rawMRutils.returnHeaderAndData('./ScanArchive_EPI_converted.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refDataArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement ramp-sampling regridding using the same algorithms implemented in the \"computeTrajectory()\" method in:\n",
    "# gadgetron_sources/toolboxes/mri/epi/EPIReconXObjectTrapezoid.h - mostly to allow comparisons to be made.\n",
    "\n",
    "# The basic idea is to take the acquired data, sampled on the ramps and flat top of the acquisition, i.e.\n",
    "#\n",
    "#                               Data Acquisition Window\n",
    "#                           <------------------------------>\n",
    "#                           .                              .\n",
    "#                           .     --------------------     .\n",
    "#                           .    /                    \\    .\n",
    "#                           .   /                      \\   .\n",
    "#                           .  /                        \\  .   \n",
    "#                           . /                          \\ .\n",
    "#                           ./                            \\.\n",
    "#                           /                              \\\n",
    "#                          /                                \\\n",
    "#                         /                                  \\\n",
    "#                        /                                    \\\n",
    "#                       /                                      \\\n",
    "#\n",
    "# where, because of the ramps, the data is now non-uniformly sampled in k-space.  Since position / location in\n",
    "# k-space is determined by the time integral of the gradient waveform up to that point, we can take the total\n",
    "# area under the ramp-sampled acquisition, divide that area evenly to determine the location of k-space points\n",
    "# after regridding / interpolation.\n",
    "\n",
    "# First, extract ramp parameters from header.\n",
    "\n",
    "traj = dataHeader.encoding[0].trajectory\n",
    "if (traj == 'epi'):\n",
    "   trajID = dataHeader.encoding[0].trajectoryDescription.identifier\n",
    "   if (trajID == 'ConventionalEPI'):\n",
    "      print (\"Trajectory for this dataset is %s, and trajectory ID is %s\" % (traj, trajID))\n",
    "\n",
    "      # Iterate over the elements of the trajectory section, and get 'long' parameters needed for EPI.\n",
    "      for i, trajValue in enumerate(dataHeader.encoding[0].trajectoryDescription.userParameterLong[:]):\n",
    "         if (trajValue.orderedContent()[0].value == 'acqDelayTime'):\n",
    "            acqDelayTime_ = trajValue.orderedContent()[1].value\n",
    "\n",
    "         if (trajValue.orderedContent()[0].value == 'rampUpTime'):\n",
    "            rampUpTime_   = trajValue.orderedContent()[1].value\n",
    "\n",
    "         if (trajValue.orderedContent()[0].value == 'flatTopTime'):\n",
    "            flatTopTime_  = trajValue.orderedContent()[1].value\n",
    "\n",
    "         if (trajValue.orderedContent()[0].value == 'rampDownTime'):\n",
    "            rampDownTime_ = trajValue.orderedContent()[1].value\n",
    "\n",
    "         if (trajValue.orderedContent()[0].value == 'numSamples'):\n",
    "            numSamples_   = trajValue.orderedContent()[1].value\n",
    "\n",
    "      for i, trajValue in enumerate(dataHeader.encoding[0].trajectoryDescription.userParameterDouble[:]):\n",
    "         if (trajValue.orderedContent()[0].value == 'dwellTime'):\n",
    "            dwellTime_    = trajValue.orderedContent()[1].value\n",
    "\n",
    "# Code for ramp-sampling from @jad11nih.\n",
    "numReadoutAcqPoints   = dataArray.shape[1]\n",
    "numReadoutReconPoints = dataHeader.encoding[0].reconSpace.matrixSize.x\n",
    "\n",
    "totalGradientTime     = rampUpTime_ + flatTopTime_ + rampDownTime_\n",
    "totalReadoutTime      = numReadoutAcqPoints * dwellTime_\n",
    "\n",
    "numGradientRampPoints = int(rampUpTime_  / dwellTime_)\n",
    "numGradientFlatPoints = int(flatTopTime_ / dwellTime_)\n",
    "\n",
    "if (numGradientFlatPoints >= numReadoutAcqPoints):\n",
    "   numAcqFlatPoints = numReadoutAcqPoints\n",
    "else:\n",
    "   numAcqFlatPoints = numGradientFlatPoints\n",
    "\n",
    "numAcqRampPoints    = int ((numReadoutAcqPoints - numAcqFlatPoints) / 2)\n",
    "\n",
    "doRampSampledRecon  = 0\n",
    "\n",
    "if (numAcqRampPoints > 0):    # i.e. Data is being acquired on EPI ramps, we have ramp-sampled data!\n",
    "   doRampSampledRecon     = 1 # Use this as flag for recon later on.\n",
    "\n",
    "   # Build gradient waveform\n",
    "   gx = np.zeros(numReadoutAcqPoints, dtype=np.float64)\n",
    "\n",
    "   numGradientSkipPoints  = numGradientRampPoints - numAcqRampPoints\n",
    "   gx[:numAcqRampPoints]  = np.linspace(numGradientSkipPoints + 0.5, numGradientRampPoints, numAcqRampPoints)\n",
    "   gx[-numAcqRampPoints:] = np.flip(gx[:numAcqRampPoints])\n",
    "\n",
    "   gx[numAcqRampPoints:numAcqRampPoints+numAcqFlatPoints] = numGradientRampPoints\n",
    "\n",
    "   # Now, compute k-space along this gradient trajectory.\n",
    "   kx    = np.cumsum(gx)\n",
    "\n",
    "   # Rescale gx and kx\n",
    "   scale = numReadoutReconPoints / kx[-1]\n",
    "   kx    = kx * scale - numReadoutReconPoints/2\n",
    "\n",
    "   # Create 'physical' pixel locations\n",
    "   x     = np.linspace (-numReadoutReconPoints/2, numReadoutReconPoints/2, numReadoutReconPoints, False)\n",
    "\n",
    "   # Now create the encoding matrix.\n",
    "   E     = np.exp(2 * np.pi * 1.0j * np.outer(kx, x)/numReadoutReconPoints)\n",
    "   pinvE = np.linalg.pinv(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCplxArray = [0.0+1.0j, 2.0+3.0j, 4.0+5.0j, 6.0+7.0j, 8.0+9.0j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as mplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computeN2GhostCorrection (angleData):\n",
    "\n",
    "   x = np.linspace(-0.5,0.5,len(angleData))\n",
    "   w = np.abs(angleData)\n",
    "   # A = np.zeros([x.size,3])\n",
    "   A = np.zeros([x.size,2])\n",
    "\n",
    "   A[:,0] = w \n",
    "   A[:,1] = w*x\n",
    "   # A[:,2] = w*x**2\n",
    "   B      = w*np.angle(angleData) # magnitude-weighted phase data\n",
    "\n",
    "   X,resid,rank,sigma = np.linalg.lstsq(A, B, rcond=None)\n",
    "\n",
    "   oefit = X[0] + X[1]*x + np.pi # + X[2]*x**2\n",
    "\n",
    "   return (np.exp(1j * oefit))\n",
    "\n",
    "\n",
    "\n",
    "def computeN2GhostCorrectionAhnMethod (angleData):\n",
    "   # based on algorithm in IEEE Trans on Med. Imag., Vol MI-6, No. 1, Pg. 32 - 36 (1987).\n",
    "   #\n",
    "   # Still start with the averaged difference between the odd and even lines.\n",
    "\n",
    "   nPoints      = len(angleData)\n",
    "   # x            = np.linspace(-0.5, 0.5, nPoints, False)\n",
    "   x            = np.linspace(-nPoints/2, nPoints/2, nPoints, False)\n",
    "\n",
    "   # This needs the range for the call to 'linspace' (above) set properly to represent phase.\n",
    "   avgPhaseDiff   = np.average([(angleData[i] * np.conj(angleData[i+1])) for i in range(nPoints - 1)])\n",
    "\n",
    "   linearPhaseFit = np.exp(-1.0j * np.angle(avgPhaseDiff) * x)\n",
    "\n",
    "   # Remove linear phase trend to compute constant phase offset.\n",
    "   linearRemoved  = angleData * linearPhaseFit\n",
    "   constantPhase  = np.average(np.angle(linearRemoved))\n",
    "   constantPhase  = np.exp(-1.0j * constantPhase)\n",
    "\n",
    "   return (constantPhase * linearPhaseFit)\n",
    "\n",
    "\n",
    "\n",
    "def loadNonComplexToComplex (nonComplexData):\n",
    "   return (nonComplexData[0::2] + 1j * nonComplexData[1::2])\n",
    "\n",
    "\n",
    "\n",
    "def oneDimTransform (data2Transform):\n",
    "   return np.fft.fftshift(np.fft.fft(np.fft.fftshift(data2Transform)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCoils   = refDataArray.shape[0]\n",
    "nNavs    = refDataArray.shape[2]\n",
    "nPhases  =    dataArray.shape[2]\n",
    "nSlices  = refDataArray.shape[3]\n",
    "nReps    = refDataArray.shape[4]\n",
    "\n",
    "if (doRampSampledRecon == 1):\n",
    "   corrData = np.zeros((nCoils, numReadoutReconPoints, nNavs, nSlices, nReps), dtype=np.complex64)\n",
    "\n",
    "   # Ramp-sampling correction already does the equivalent of a DFT to image space.\n",
    "   for s in range (nSlices):\n",
    "      for r in range (nReps):\n",
    "         for c in range (nCoils):\n",
    "            for n in range (nNavs):\n",
    "               corrData[c, :, n, s, r] = pinvE @ refDataArray[c, :, n, s, r]\n",
    "else:\n",
    "   corrData = np.zeros(refDataArray.shape, dtype=np.complex64)\n",
    "   # Transform and store reference lines to compute phase corrections.\n",
    "   corrData[:, :, 0:nNavs:1, :, :] = np.fft.fftshift(np.fft.fft(np.fft.fftshift(refDataArray[:, :, 0:nNavs:1, :, :],\n",
    "                                                                axes=[1]),\n",
    "                                                     axis=1),\n",
    "                                     axes=[1])\n",
    "for s in range (nSlices):\n",
    "   for r in range (nReps):\n",
    "      for c in range (nCoils):\n",
    "         # Store computed odd - even phase difference fit back in line '0' of reference data array.  Check\n",
    "         # vendor as each vendor handles packing EPI reference data a little differently.\n",
    "         if (dataHeader.acquisitionSystemInformation.systemVendor == 'GE MEDICAL SYSTEMS'):\n",
    "            # GE has 4, but first line (index value == 0) doesn't contain useful EPI reference data.\n",
    "            epiRefStart = 1\n",
    "            # angleData = (corrData[c, :, 1, s, r] + corrData[c, :, 3, s, r]) * 0.5 * np.conj(corrData[c, :, 2, s, r])\n",
    "         else:\n",
    "            # Siemens data has 3 EPI reference lines, all holding relveant data.\n",
    "            epiRefStart = 0\n",
    "            # angleData = (corrData[c, :, 0, s, r] + corrData[c, :, 2, s, r]) * 0.5 * np.conj(corrData[c, :, 1, s, r])\n",
    "\n",
    "         angleData = ((np.average(corrData[c, :,  epiRefStart::2,    s, r], axis=1)) *\n",
    "               np.conj(np.average(corrData[c, :, (epiRefStart+1)::2, s, r], axis=1)))\n",
    "\n",
    "         # Use 'raw' phase difference between odd/even lines directly, normalized by magnitude (suggested by @jad11).\n",
    "         # corrData[c, :, 0, s, r] = angleData / abs(angleData)\n",
    "\n",
    "         # Or call polynomial phase fitting routine.\n",
    "         corrData[c, :, 0, s, r] = computeN2GhostCorrection(angleData)\n",
    "\n",
    "         # Use Cho/Ahn method, which should be more robust to phase wraps - linear term currently not correct.\n",
    "         # corrData[c, :, 0, s, r] = computeN2GhostCorrectionAhnMethod(angleData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging cell - checking contents of reference lines and results of computations to fit phase.\n",
    "\n",
    "fig, ax     = mplt.subplots(1, 1, sharex=True, sharey=True)\n",
    "\n",
    "item2Plot   = corrData[4, :, :, 1, 3]\n",
    "# item2Plot   = np.zeros ((100, 4) , dtype = np.complex64)\n",
    "# item2Plot   = corrData[15, 70:170, 0, 1, 3]\n",
    "# item2Plot   = phaseProfile\n",
    "\n",
    "ax.plot((np.angle(item2Plot[:,:])), label=str('phase'))\n",
    "# ax.plot(np.abs(item2Plot), label=str('mag'))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply phase corrections.\n",
    "\n",
    "if (doRampSampledRecon == 1):\n",
    "   correctedArray   = np.zeros((nCoils, numReadoutReconPoints, nPhases, nSlices, nReps), dtype=np.complex64)\n",
    "   xFormedInReadout = np.zeros((nCoils, numReadoutReconPoints, nPhases, nSlices, nReps), dtype=np.complex64)\n",
    "\n",
    "   for s in range (nSlices):\n",
    "      for r in range (nReps):\n",
    "         for c in range (nCoils):\n",
    "            for n in range (nPhases):\n",
    "               xFormedInReadout[c, :, n, s, r] = pinvE @ dataArray[c, :, n, s, r]\n",
    "else:\n",
    "   correctedArray   = np.zeros (dataArray.shape, dtype = np.complex64)\n",
    "   xFormedInReadout = np.fft.fftshift(np.fft.fft(np.fft.fftshift(dataArray, axes=[1]), axis=1), axes=[1])\n",
    "\n",
    "# Apply phase correction to alternating lines.\n",
    "correctedArray[:, :, 0:dataArray.shape[2]:2, :, :] = (xFormedInReadout[:, :, 0:dataArray.shape[2]:2, :, :]\n",
    "                                                          *   corrData[:, :, 0:1:1,                  :, :])\n",
    "\n",
    "# Then copy in data that were not corrected, i.e. alternate lines NOT corrected above.\n",
    "correctedArray[:, :, 1:dataArray.shape[2]:2, :, :] =  xFormedInReadout[:, :, 1:dataArray.shape[2]:2, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSpace = np.fft.fftshift(np.fft.fft(np.fft.fftshift(correctedArray, axes=[2]), axis=2), axes=[2])\n",
    "# imageSpace = np.fft.fftshift(np.fft.fft2(dataArray, axes=(1,2)), axes=(1,2))\n",
    "# rawMRutils.computeAndPlot(imageSpace)\n",
    "plottedFigures = mplt.figure(figsize=(12,18))\n",
    "\n",
    "subImages = plottedFigures.add_subplot(1, 1, (1))\n",
    "\n",
    "disp = abs(imageSpace[:, :, :, 1, 3])\n",
    "# subImages.imshow(disp)\n",
    "subImages.imshow(np.sqrt(np.sum(disp*disp, axis=0)), 'viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
